#!/bin/sh

set -e

MODEL_URL=${MODEL_URL:-"TheBloke/Mistral-7B-OpenOrca-GGUF"}
QUANT_TYPE=${QUANT_TYPE:-"Q5_K_S"}
MODEL_PATH=$(python3 GetModel.py "$MODEL_URL" "$QUANT_TYPE")
MAX_TOKENS=${MAX_TOKENS:-8192}
THREADS=${THREADS:-($(nproc) - 1)}
THREADS_BATCH=${THREADS_BATCH:-$THREADS}
GPU_LAYERS=${GPU_LAYERS:-0}
MAIN_GPU=${MAIN_GPU:-0}
BATCH_SIZE=${BATCH_SIZE:-512}
LLAMACPP_PORT=${LLAMACPP_PORT:-8090}
OPENAI_ENDPOINT_PORT=${OPENAI_ENDPOINT_PORT:-8091}
UVICORN_WORKERS="${UVICORN_WORKERS:-2}"

python3 GetModel.py "$MODEL_URL" "$QUANT_TYPE"

./app/tools.sh --server -m $MODEL_PATH -c $MAX_TOKENS -ngl $GPU_LAYERS -t $THREADS -tb $THREADS_BATCH -mg $MAIN_GPU -b $BATCH_SIZE --host 0.0.0.0 --port $LLAMACPP_PORT &
uvicorn app:app --host 0.0.0.0 --port 8091 --workers $UVICORN_WORKERS --proxy-headers