version: '3.8'

services:
  local-llm:
    build:
      context: .
      dockerfile: cuda.Dockerfile
    environment:
      - GPU_LAYERS=0
      - LOCAL_LLM_API_KEY=${LOCAL_LLM_API_KEY-}
      - DEFAULT_MODEL=${DEFAULT_MODEL-phi-2-dpo}
      - VOICE_ENABLED=true
    ports:
      - "8091:8091"
    volumes:
      - ./models:/app/models
      - ./outputs:/app/outputs
      - ./voices:/app/voices