{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezlocalai\n",
    "\n",
    "Open this notebook in [Google Colab.](https://colab.research.google.com/)\n",
    "\n",
    "Set the resources to T4 GPU, free tier.\n",
    "\n",
    "It takes several minutes to install dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update --fix-missing && apt-get upgrade -y\n",
    "!apt-get install -y --fix-missing --no-install-recommends git build-essential cmake gcc g++ portaudio19-dev ffmpeg libportaudio2 libasound-dev python3 python3-pip wget ocl-icd-opencl-dev opencl-headers clinfo libclblast-dev libopenblas-dev ninja-build python3.10-dev\n",
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!ln -s /usr/bin/python3 /usr/bin/python\n",
    "!apt-get clean && rm -rf /var/lib/apt/lists/* /var/cache/apt/* /tmp/* /var/tmp/*\n",
    "!python3 -m pip install --upgrade pip cmake scikit-build setuptools wheel pyngrok --no-cache-dir\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir\n",
    "!rm -rf sample_data .config\n",
    "!git clone https://github.com/DevXT-LLC/ezlocalai .\n",
    "!pip install -r cuda-requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the server\n",
    "\n",
    "Set the `NGROK_TOKEN` to use NGROK to expose your ezlocalai server to the public with as simple as an API key. [Get your free NGROK_TOKEN here.](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "\n",
    "You can see the ngrok URL in the cell output after running the cell.\n",
    "\n",
    "Set the `LLM_TO_USE` with the name of the model from the models list. We will use `phi-2-dpo` for this example since it is a smaller model that can still be useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_TO_USE = \"phi-2-dpo\"\n",
    "\n",
    "# Add your NGROK_TOKEN to your colab secrets if using Google Colab (Key logo on the left)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
    "    if not NGROK_TOKEN:\n",
    "        raise\n",
    "except:\n",
    "    # If you're not using Google Colab, enter your NGROK_TOKEN below.\n",
    "    NGROK_TOKEN = \"Enter your ngrok token here\"\n",
    "if NGROK_TOKEN != \"Enter your ngrok token here\":\n",
    "    with open('.env', 'r') as file:\n",
    "        filedata = file.read()\n",
    "    filedata = filedata.replace('NGROK_TOKEN=\\n', f'NGROK_TOKEN={NGROK_TOKEN}\\n')\n",
    "    filedata = filedata.replace('DEFAULT_MODEL=phi-2-dpo', f'DEFAULT_MODEL={LLM_TO_USE}')\n",
    "    with open('.env', 'w') as file:\n",
    "        file.write(filedata)\n",
    "!uvicorn app:app --host 0.0.0.0 --port 8091 --workers 1 --proxy-headers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
