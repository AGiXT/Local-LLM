name: Dev - Build and Test

on:
  push:
    branches-ignore:
      - main
  workflow_dispatch:

jobs:
  build-local-llm:
    runs-on: LargeRunner
    strategy:
      matrix:
        include:
          - name: "CPU"
            dockerfile: "Dockerfile"
            platforms: "linux/amd64"
            tag_name: "cpu-dev"
          - name: "CUDA"
            dockerfile: "cuda.Dockerfile"
            platforms: "linux/amd64"
            tag_name: "cuda-dev"
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract GitHub info
        run: |
          echo "BRANCH_NAME=$(echo ${GITHUB_REF#refs/heads/} | sed 's/[^a-zA-Z0-9._-]/-/g')" >> $GITHUB_ENV 
          echo "GITHUB_USER=$(echo ${{ github.actor }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          echo "REPO_NAME=$(echo ${{ github.repository }} | cut -d'/' -f 2 | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
        id: extract_branch

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ env.GITHUB_USER }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./${{ matrix.dockerfile }}
          platforms: ${{ matrix.platforms }}
          push: true
          cache-from: type=gha
          cache-to: type=gha,mode=max
          tags: |
            ghcr.io/agixt/${{ env.REPO_NAME }}:${{ matrix.tag_name }}
            ghcr.io/agixt/${{ env.REPO_NAME }}:${{ matrix.tag_name }}-${{ env.BRANCH_NAME }}
            ghcr.io/agixt/${{ env.REPO_NAME }}:${{ matrix.tag_name }}-${{ env.BRANCH_NAME }}-${{ github.sha }}

  test-local-llm:
    uses: josh-xt/AGiXT/.github/workflows/operation-test-with-jupyter.yml@main
    with:
      notebook: tests/tests.ipynb
      image: ghcr.io/agixt/local-llm:cpu-dev
      port: "8091"
      additional-python-dependencies: openai requests
    needs: build-local-llm
